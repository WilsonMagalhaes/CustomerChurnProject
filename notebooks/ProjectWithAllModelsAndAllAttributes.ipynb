{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f4_k3zfP6Ay_"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "df2 = pd.read_csv('Telco_Customer_Churn.csv')\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler, OrdinalEncoder, MinMaxScaler\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from imblearn.combine import SMOTEENN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hFNW6VGw7CHS"
      },
      "outputs": [],
      "source": [
        "def transformSplit(df):\n",
        "  import numpy as np\n",
        "  from sklearn.preprocessing import OneHotEncoder, StandardScaler, OrdinalEncoder, MinMaxScaler\n",
        "  from sklearn.compose import ColumnTransformer\n",
        "  from sklearn.impute import SimpleImputer\n",
        "  from sklearn.model_selection import train_test_split\n",
        "  from sklearn.pipeline import Pipeline\n",
        "  from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "  from sklearn.linear_model import LogisticRegression\n",
        "  from imblearn.combine import SMOTEENN\n",
        "\n",
        "  # Load the dataset\n",
        "  df = pd.read_csv('Telco_Customer_Churn.csv')\n",
        "\n",
        "  # Convert 'TotalCharges' to numeric, coercing errors\n",
        "  df['TotalCharges'] = pd.to_numeric(df['TotalCharges'], errors='coerce')\n",
        "  df['Tenure_MonthlyCharges'] = df['tenure'] * df['MonthlyCharges']\n",
        "\n",
        "  # Drop the 'customerID' column\n",
        "  df.drop(\"customerID\", axis=1, inplace=True)\n",
        "  X_train, X_test = train_test_split(df, test_size=0.4, random_state=42)\n",
        "  X_test, X_validation = train_test_split(X_test, test_size=0.5, random_state=42)\n",
        "\n",
        "  # Separate the target variable 'Churn' from the features\n",
        "  y_train = X_train[['Churn']]\n",
        "  X_train.drop(\"Churn\", axis=1, inplace=True)\n",
        "  y_test = X_test[['Churn']]\n",
        "  X_test.drop(\"Churn\", axis=1, inplace=True)\n",
        "  y_validation = X_validation[['Churn']]\n",
        "  X_validation.drop(\"Churn\", axis=1, inplace=True)\n",
        "\n",
        "\n",
        "\n",
        "  return X_train, X_test, X_validation, y_train, y_test, y_validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aRiRv-SG9PuM"
      },
      "outputs": [],
      "source": [
        "def transformX(df):\n",
        "    print(df.iloc[1, :])\n",
        "    # Identify categorical and numeric columns\n",
        "    categorical_columns_initial = df.select_dtypes(include=['object', 'category']).columns\n",
        "    categorical_columns_two_options = [col for col in categorical_columns_initial if df[col].nunique() == 2]\n",
        "    categorical_columns = [col for col in categorical_columns_initial if col not in categorical_columns_two_options]\n",
        "\n",
        "    numeric_columns = df.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
        "\n",
        "    # Remove 'SeniorCitizen' from numeric columns to passthrough without scaling\n",
        "    if 'SeniorCitizen' in numeric_columns:\n",
        "        numeric_columns.remove('SeniorCitizen')\n",
        "\n",
        "    # Define preprocessing pipeline for numeric and categorical columns\n",
        "\n",
        "    # Numeric pipeline (Imputation + Scaling)\n",
        "    numeric_transformer = Pipeline(steps=[\n",
        "        ('imputer', SimpleImputer(strategy='median')),  # Impute missing numeric values\n",
        "        ('scaler', StandardScaler())  # Scale the numeric features\n",
        "    ])\n",
        "\n",
        "    # Categorical pipeline (Two-option categories: Ordinal Encoding, Other Categorical: OneHotEncoding)\n",
        "    categorical_two_opt_transformer = Pipeline(steps=[\n",
        "        ('imputer', SimpleImputer(strategy='most_frequent')),  # Impute missing categorical (binary)\n",
        "        ('onehot', OrdinalEncoder())  # Ordinal encode binary categories\n",
        "    ])\n",
        "\n",
        "    categorical_transformer = Pipeline(steps=[\n",
        "        ('imputer', SimpleImputer(strategy='most_frequent')),  # Impute missing categorical\n",
        "        ('onehot', OneHotEncoder(drop='first'))  # One-hot encode other categorical features\n",
        "    ])\n",
        "\n",
        "    # Combine all the transformers into a ColumnTransformer\n",
        "    full_pipeline = ColumnTransformer(transformers=[\n",
        "        ('num', numeric_transformer, numeric_columns),\n",
        "        ('cat_two_opt', categorical_two_opt_transformer, categorical_columns_two_options),\n",
        "        ('cat', categorical_transformer, categorical_columns),\n",
        "        ('passthrough', 'passthrough', ['SeniorCitizen'])  # Pass 'SeniorCitizen' unchanged\n",
        "    ])\n",
        "\n",
        "    # Apply the full pipeline to the data\n",
        "    df_prepared = full_pipeline.fit_transform(df)\n",
        "\n",
        "    # Get new column names after one-hot encoding\n",
        "    encoded_categorical_columns = full_pipeline.transformers_[2][1]['onehot'].get_feature_names_out(categorical_columns)\n",
        "\n",
        "    # Combine numeric, ordinal, and one-hot encoded feature names\n",
        "    all_columns = numeric_columns + categorical_columns_two_options + list(encoded_categorical_columns) + ['SeniorCitizen']\n",
        "\n",
        "    # Convert the transformed NumPy array back to a DataFrame\n",
        "    df_prepared = pd.DataFrame(df_prepared, columns=all_columns)\n",
        "\n",
        "\n",
        "    return df_prepared"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A58SjKA_9lMX"
      },
      "outputs": [],
      "source": [
        "def transform_target(target_variable):\n",
        "  ordinal_encoder = OrdinalEncoder()\n",
        "  treated = ordinal_encoder.fit_transform(target_variable)\n",
        "  return treated"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8p0sjylN9qlB"
      },
      "outputs": [],
      "source": [
        "def transformALL(df):\n",
        "  X_train, X_test, X_validation, y_train, y_test, y_validation = transformSplit(df)\n",
        "  X_train = transformX(X_train)\n",
        "  X_test = transformX(X_test)\n",
        "  X_validation = transformX(X_validation)\n",
        "  y_train = transform_target(y_train)\n",
        "  y_test = transform_target(y_test)\n",
        "  y_validation = transform_target(y_validation)\n",
        "  sm = SMOTEENN()\n",
        "  X_train, y_train = sm.fit_resample(X_train, y_train)\n",
        "  return X_train, X_test, X_validation, y_train, y_test, y_validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X5HCU2Qp-UNH"
      },
      "outputs": [],
      "source": [
        "def returnBestAtt(df, n_att):\n",
        "\n",
        "  from sklearn.feature_selection import SelectKBest, f_classif\n",
        "  from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "  X_train, X_test, X_validation, y_train, y_test, y_validation = transformALL(df)\n",
        "  # Select the top xx features using f_classif\n",
        "  selector = SelectKBest(score_func=f_classif, k=n_att)\n",
        "  X_train_new = selector.fit_transform(X_train, y_train)\n",
        "\n",
        "  # Get selected feature indices and names\n",
        "  selected_feature_indices = selector.get_support(indices=True)\n",
        "  selected_feature_names = X_train.columns[selected_feature_indices]\n",
        "\n",
        "  # Transform the test data using the same feature selection\n",
        "  X_test_new = selector.transform(X_test)\n",
        "  X_validation_new = selector.transform(X_validation)\n",
        "\n",
        "  return X_train_new, X_test_new, X_validation_new, y_train, y_test, y_validation, selected_feature_names"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aGnmmb9fAZDB"
      },
      "outputs": [],
      "source": [
        "def useModel(model, param_grid, X_train, y_train, X_test, y_test):\n",
        "  from sklearn.model_selection import GridSearchCV\n",
        "  from sklearn.metrics import accuracy_score, confusion_matrix, precision_recall_curve, f1_score, precision_score, recall_score\n",
        "  grid = GridSearchCV(model, param_grid, cv=5)\n",
        "  grid.fit(X_train, y_train)\n",
        "  print(f\"Best Params: {grid.best_params_}\")\n",
        "  print(f\"Best Score: {grid.best_score_}\")\n",
        "  best_model = grid.best_estimator_\n",
        "  y_pred = best_model.predict(X_test)\n",
        "  precision = precision_score(y_test, y_pred)\n",
        "  recall = recall_score(y_test, y_pred)\n",
        "  print(f\"Precision: {precision:.2f}, Recall: {recall:.2f}\")\n",
        "  print(f\"Accuracy: {accuracy_score(y_test, y_pred)}\")\n",
        "  print(f\"Confusion Matrix: {confusion_matrix(y_test, y_pred, normalize = 'true')}\")\n",
        "  return best_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1J3JPhVjHO0C"
      },
      "outputs": [],
      "source": [
        "def useModelBestThreshold(model, X_train, y_train, X_test, y_test):\n",
        "  from sklearn.metrics import accuracy_score, confusion_matrix, precision_recall_curve, f1_score, precision_score, recall_score\n",
        "\n",
        "  y_probs = model.predict_proba(X_test)[:, 1]  # Probabilities for the positive class\n",
        "  precisions, recalls, thresholds = precision_recall_curve(y_test, y_probs)\n",
        "\n",
        "  # Compute F1 score for each threshold\n",
        "  f1_scores = 2 * (precisions * recalls) / (precisions + recalls)\n",
        "  optimal_threshold = thresholds[f1_scores.argmax()]\n",
        "\n",
        "  print(f'Optimal Threshold: {optimal_threshold}, Best F1 Score: {f1_scores.max()}')\n",
        "\n",
        "  # Predict with the new threshold\n",
        "  y_pred_opt = (y_probs >= optimal_threshold).astype(int)\n",
        "\n",
        "  accuracy = accuracy_score(y_test, y_pred_opt)\n",
        "\n",
        "  precision = precision_score(y_test, y_pred_opt)\n",
        "  recall = recall_score(y_test, y_pred_opt)\n",
        "\n",
        "  print(f\"Precision: {precision:.2f}, Recall: {recall:.2f}\")\n",
        "  print(f\"Accuracy with best Threshold: {accuracy}\")\n",
        "  print(confusion_matrix(y_test, y_pred_opt, normalize = 'true'))\n",
        "  print(X_test.columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "toJB-rWoMsxR"
      },
      "outputs": [],
      "source": [
        "def testAllAtributes(df, model, param_grid):\n",
        "  for i in range(df.shape[1] - 1, df.shape[1]):\n",
        "    X_train_new, X_test_new, X_validation_new, y_train, y_test, y_validation, selected_feature_names = returnBestAtt(df, i)\n",
        "    best_model = useModel(model, param_grid, X_train_new, y_train, X_test_new, y_test)\n",
        "    print(\"\")\n",
        "    print(\"\")\n",
        "    print(\"\")\n",
        "    print(\"\")\n",
        "    print(\"\")\n",
        "    useModelBestThreshold(best_model, X_train_new, y_train, X_test_new, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2G8zfOWuNk3x"
      },
      "outputs": [],
      "source": [
        "param_grid = {'C': [0.1, 1, 10],\n",
        "         'penalty': ['l1', 'l2']}\n",
        "\n",
        "model = LogisticRegression(class_weight='balanced', solver = 'liblinear', random_state=42)\n",
        "testAllAtributes(df2, model, param_grid)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0zoOU63KQ9ub"
      },
      "outputs": [],
      "source": [
        "from sklearn.svm import SVC\n",
        "svm = SVC(class_weight='balanced', probability=True, random_state=42)\n",
        "param_gridSVM = {'C': [0.1, 1, 10],\n",
        "         'gamma': ['scale', 'auto']}\n",
        "\n",
        "testAllAtributes(df2, svm, param_gridSVM)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_jYR33c-aVix"
      },
      "outputs": [],
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "knn = KNeighborsClassifier()\n",
        "param_gridKNN = {'n_neighbors': [3, 5, 7],\n",
        "         'weights': ['uniform', 'distance']}\n",
        "\n",
        "testAllAtributes(df2, knn, param_gridKNN)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g9hEbZx7a9vd"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "rf = RandomForestClassifier(class_weight='balanced', random_state=42)\n",
        "param_gridRF = {'n_estimators': [50, 100, 200],\n",
        "         'max_depth': [None, 10, 20]}\n",
        "\n",
        "testAllAtributes(df2, rf, param_gridRF)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FAfBvp01fmCz"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "gb = GradientBoostingClassifier(random_state=42)\n",
        "param_gridGB = {'n_estimators': [50, 100, 200],\n",
        "         'learning_rate': [0.05, 0.1, 0.5]}\n",
        "\n",
        "testAllAtributes(df2, gb, param_gridGB)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dSfB93WpiJZ1"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "ab = AdaBoostClassifier(algorithm='SAMME', random_state=42)\n",
        "param_gridAB = {'n_estimators': [50, 100, 200],\n",
        "         'learning_rate': [0.05, 0.1, 0.5]}\n",
        "\n",
        "testAllAtributes(df2, ab, param_gridAB)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7eCTAO4-laym"
      },
      "outputs": [],
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "dt = DecisionTreeClassifier(random_state=42)\n",
        "param_gridDT = {'max_depth': [None, 10, 20],\n",
        "         'min_samples_split': [2, 5, 10]}\n",
        "\n",
        "testAllAtributes(df2, dt, param_gridDT)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z2y2nk0Pl5Y9"
      },
      "outputs": [],
      "source": [
        "from sklearn.naive_bayes import GaussianNB\n",
        "\n",
        "nb = GaussianNB()\n",
        "testAllAtributes(df2, nb, {})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eZH5hrujmuv_"
      },
      "outputs": [],
      "source": [
        "def testAllAtributesValidation(df, model, param_grid):\n",
        "  for i in range(1, df.shape[1]):\n",
        "    X_train_new, X_test_new, X_validation_new, y_train, y_test, y_validation, selected_feature_names = returnBestAtt(df, i)\n",
        "    best_model = useModel(model, param_grid, X_train_new, y_train, X_validation_new, y_validation)\n",
        "    print(\"\")\n",
        "    print(\"\")\n",
        "    print(\"\")\n",
        "    print(\"\")\n",
        "    print(\"\")\n",
        "    useModelBestThreshold(best_model, X_train_new, y_train, X_validation_new, y_validation)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LnRbW3sOm_Rw"
      },
      "outputs": [],
      "source": [
        "testAllAtributesValidation(df2, svm, param_gridSVM)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cV-PZea8nDRK"
      },
      "outputs": [],
      "source": [
        "testAllAtributesValidation(df2, rf, param_gridRF)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i0PbUrygnGcl"
      },
      "outputs": [],
      "source": [
        "testAllAtributesValidation(df2, gb, param_gridGB)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dl8GkISFnH2r"
      },
      "outputs": [],
      "source": [
        "testAllAtributesValidation(df2, ab, param_gridAB)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3qFRfqscnKN8"
      },
      "outputs": [],
      "source": [
        "testAllAtributesValidation(df2, dt, param_gridDT)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X6YO61BbnORR"
      },
      "outputs": [],
      "source": [
        "testAllAtributesValidation(df2, knn, param_gridKNN)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EpMn4RE7ncD7"
      },
      "outputs": [],
      "source": [
        "testAllAtributesValidation(df2, nb, {})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z-hocRd-nnDz"
      },
      "outputs": [],
      "source": [
        "testAllAtributesValidation(df2, model, param_grid)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}